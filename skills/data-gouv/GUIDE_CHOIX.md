# Guide de choix : Librairie Python vs MCP officiel

## TL;DR - Aide-mÃ©moire rapide

**Question simple** : "Je veux juste tÃ©lÃ©charger et analyser des donnÃ©es"  
â†’ **Utilisez notre librairie Python** ğŸ

**Question complexe** : "Je veux faire des requÃªtes SQL sur toute la base data.gouv.fr"  
â†’ **Utilisez le MCP officiel** ğŸš€

---

## Arbre de dÃ©cision
```
Vous voulez...
â”‚
â”œâ”€ TÃ©lÃ©charger un CSV et l'analyser ?
â”‚  â””â”€â†’ Librairie Python âœ…
â”‚
â”œâ”€ Travailler offline / avec cache ?
â”‚  â””â”€â†’ Librairie Python âœ…
â”‚
â”œâ”€ Faire un script automatisÃ© simple ?
â”‚  â””â”€â†’ Librairie Python âœ…
â”‚
â”œâ”€ RequÃªte SQL complexe sur plusieurs datasets ?
â”‚  â””â”€â†’ MCP officiel âœ…
â”‚
â”œâ”€ CrÃ©er/modifier des datasets sur data.gouv.fr ?
â”‚  â””â”€â†’ MCP officiel âœ…
â”‚
â””â”€ Poser des questions en langage naturel ?
   â””â”€â†’ MCP officiel âœ…
```

---

## Cas d'usage par approche

### Librairie Python

#### âœ… Parfait pour :

**1. Analyse hebdomadaire automatisÃ©e**
```python
# Cron job tous les lundis
from datagouv import DataGouvAPI

api = DataGouvAPI()
df = api.load_csv(url, cache=True)
df_region = df[df['region'] == '75']
send_report(df_region)
```

**2. DÃ©veloppement local**
```python
# ItÃ©ration rapide
df = api.load_csv(url)
print(df.columns)
df.groupby('age')['doses'].sum()
```

**3. Notebooks Jupyter**
```python
# Exploration interactive
api = DataGouvAPI()
df = api.load_csv(url)
df.plot()
```

**4. Scripts portables**
```python
# Fonctionne partout : laptop, serveur, CI/CD
# Pas de dÃ©pendances lourdes
```

**5. Formation / PÃ©dagogie**
```python
# Code simple et clair
# Facile Ã  comprendre et modifier
```

---

### MCP officiel

#### âœ… Parfait pour :

**1. Questions ad-hoc complexes**
```
"Trouve tous les dÃ©partements oÃ¹ le taux de vaccination 
des 65+ a augmentÃ© de plus de 30% par rapport Ã  l'annÃ©e derniÃ¨re"
```

**2. Recherche multi-datasets**
```
"Compare la qualitÃ© de l'eau et les taux de vaccination 
dans les communes de plus de 50 000 habitants"
```

**3. CrÃ©ation de datasets**
```
"CrÃ©e un nouveau dataset avec les donnÃ©es agrÃ©gÃ©es 
que je viens de calculer"
```

**4. IntÃ©gration dans des Ã©diteurs**
```
# Utilisez directement dans Claude Desktop, Cursor
# Pas besoin de coder
```

**5. RequÃªtes en langage naturel**
```
"Quelle commune a la meilleure qualitÃ© d'eau 
en Charente-Maritime ?"
```

---

## Comparaison dÃ©taillÃ©e

### Installation

**Librairie Python**
```bash
pip install pandas requests openpyxl
# C'est tout !
```

**MCP officiel**
```bash
git clone https://github.com/datagouv/datagouv-mcp
cd datagouv-mcp
# + installer Docker
# + configurer Hydra (PostgreSQL)
# + configurer le client MCP
# + dÃ©marrer le serveur
```

**Gagnant** : ğŸ Librairie Python (10x plus simple)

---

### Performance

**Librairie Python**
- TÃ©lÃ©chargement : ~10-20 sec pour un CSV moyen
- Cache : 0 sec si dÃ©jÃ  tÃ©lÃ©chargÃ©
- Offline : Fonctionne sans Internet

**MCP officiel**
- RequÃªte SQL : ~1-5 sec (donnÃ©es indexÃ©es)
- Pas de cache local
- NÃ©cessite connexion permanente

**Gagnant** : âš–ï¸ Ã‰galitÃ© (dÃ©pend du cas d'usage)

---

### FlexibilitÃ©

**Librairie Python**
```python
# ContrÃ´le total du code
df = api.load_csv(url)
df['custom_column'] = df['col1'] * 2
df.to_csv('result.csv')
```

**MCP officiel**
```
# Questions en langage naturel
# Moins de contrÃ´le prÃ©cis
```

**Gagnant** : ğŸ Librairie Python (pour les dÃ©veloppeurs)

---

### Puissance

**Librairie Python**
- TÃ©lÃ©chargement et analyse de datasets individuels
- Pas de requÃªtes SQL complexes
- Pas de recherche multi-datasets

**MCP officiel**
- RequÃªtes SQL sur toute la base Hydra
- Recherche dans tous les datasets
- CrÃ©ation de nouveaux datasets

**Gagnant** : ğŸš€ MCP officiel (pour requÃªtes complexes)

---

## ScÃ©narios rÃ©els

### ScÃ©nario 1 : Rapport hebdomadaire

**Besoin** : Envoyer un rapport tous les lundis sur les vaccinations en Nouvelle-Aquitaine

**Solution** : ğŸ Librairie Python

**Pourquoi** :
- Simple
- Cache local (pas de re-tÃ©lÃ©chargement)
- Fonctionne mÃªme si data.gouv.fr est down
- Facile Ã  automatiser (cron)
```python
# script_hebdo.py
from datagouv import DataGouvAPI

api = DataGouvAPI()
df = api.load_csv(url, cache=True)
df_na = df[df['region'] == '75']
send_email(generate_report(df_na))
```

---

### ScÃ©nario 2 : Question ponctuelle complexe

**Besoin** : "Quelles sont les 10 communes avec le meilleur taux de vaccination ET la meilleure qualitÃ© d'eau ?"

**Solution** : ğŸš€ MCP officiel

**Pourquoi** :
- NÃ©cessite de croiser 2 datasets
- RequÃªte SQL complexe
- Pas besoin de coder
```
"Croise les donnÃ©es de vaccination IQVIA et de qualitÃ© de l'eau 
pour trouver les 10 communes avec les meilleurs scores sur les deux"
```

---

### ScÃ©nario 3 : Pipeline de donnÃ©es

**Besoin** : ETL quotidien qui tÃ©lÃ©charge, nettoie, transforme et stocke les donnÃ©es

**Solution** : ğŸ Librairie Python

**Pourquoi** :
- ContrÃ´le total du pipeline
- Peut tourner sur un serveur sans interface
- Robuste et prÃ©visible
```python
# etl_pipeline.py
from datagouv import DataGouvAPI

api = DataGouvAPI()
df = api.load_csv(url)
df_clean = clean_data(df)
df_transform = transform(df_clean)
df_transform.to_sql('vaccinations', engine)
```

---

### ScÃ©nario 4 : Exploration interactive

**Besoin** : Explorer les donnÃ©es pour comprendre leur structure

**Solution** : ğŸ Librairie Python (+ Jupyter)

**Pourquoi** :
- ItÃ©ration rapide
- Visualisations inline
- Pas besoin de serveur
```python
# Dans Jupyter
from datagouv import DataGouvAPI

api = DataGouvAPI()
df = api.load_csv(url)

# Explorer
df.head()
df.describe()
df.plot()
```

---

### ScÃ©nario 5 : Recherche dans toute la base

**Besoin** : "Trouve tous les datasets qui mentionnent 'vaccination' ET qui ont des donnÃ©es pour 2025"

**Solution** : ğŸš€ MCP officiel

**Pourquoi** :
- Recherche dans toute la base Hydra
- Pas besoin de connaÃ®tre les datasets Ã  l'avance
```
"Recherche tous les datasets liÃ©s Ã  la vaccination 
qui contiennent des donnÃ©es pour 2025"
```

---

## Workflow hybride recommandÃ©

### Phase 1 : Exploration (Librairie Python)
```python
from datagouv import DataGouvAPI

api = DataGouvAPI()

# Explorer les datasets disponibles
results = api.search_datasets("vaccination")
for ds in results['data']:
    print(ds['title'])

# TÃ©lÃ©charger et explorer
df = api.load_csv(url)
print(df.columns)
print(df.describe())
```

### Phase 2 : Questions complexes (MCP)
```
"Maintenant que j'ai explorÃ©, peux-tu me faire une analyse SQL 
qui compare les vaccinations par tranche d'Ã¢ge entre toutes les rÃ©gions ?"
```

### Phase 3 : Production (Librairie Python)
```python
# Script final automatisÃ©
from datagouv import DataGouvAPI

def daily_analysis():
    api = DataGouvAPI()
    df = api.load_csv(url, cache=True)
    # ... logique mÃ©tier ...
    save_results(df)

# Cron : tous les jours Ã  8h
```

---

## Matrice de dÃ©cision

| CritÃ¨re | Lib Python | MCP officiel |
|---------|------------|--------------|
| **SimplicitÃ©** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ |
| **Setup rapide** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ |
| **Offline** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ğŸ”´ğŸ”´ |
| **Cache local** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ğŸ”´ğŸ”´ |
| **RequÃªtes SQL** | ğŸ”´ğŸ”´ğŸ”´ | ğŸŸ¢ğŸŸ¢ğŸŸ¢ |
| **Multi-datasets** | ğŸ”´ğŸ”´ | ğŸŸ¢ğŸŸ¢ğŸŸ¢ |
| **CrÃ©ation datasets** | ğŸ”´ğŸ”´ğŸ”´ | ğŸŸ¢ğŸŸ¢ğŸŸ¢ |
| **PortabilitÃ©** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ |
| **Automatisation** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ |
| **PÃ©dagogie** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸ”´ğŸ”´ |

---

## Conclusion

**Utilisez les DEUX selon vos besoins !**

- **80% du temps** : Librairie Python (simple, rapide, portable)
- **20% du temps** : MCP officiel (requÃªtes complexes, crÃ©ation)

**La v2.0.0 du skill vous donne accÃ¨s aux deux approches** avec une documentation claire pour choisir la bonne mÃ©thode au bon moment.

---

**Version** : 2.0.0  
**DerniÃ¨re mise Ã  jour** : 2025-12-02
